{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7611307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"Taxi-v3\", render_mode = \"human\")\n",
    "\n",
    "print(env.observation_space.n)\n",
    "print(env.action_space.n)\n",
    "\n",
    "\n",
    "for _ in range(1):\n",
    "    observation = env.reset()[0]\n",
    "    \n",
    "    for _ in range(10):\n",
    "        env.render() #GUI 출력\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "        observation, reward, done, _, info = env.step(action)\n",
    "        print(\"action\", action, \"reward\", reward)\n",
    "        \n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e679aca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Episode: 100\n",
      "Episode: 200\n",
      "Episode: 300\n",
      "Episode: 400\n",
      "Episode: 500\n",
      "Episode: 600\n",
      "Episode: 700\n",
      "Episode: 800\n",
      "Episode: 900\n",
      "Episode: 1000\n",
      "Episode: 1100\n",
      "Episode: 1200\n",
      "Episode: 1300\n",
      "Episode: 1400\n",
      "Episode: 1500\n",
      "Episode: 1600\n",
      "Episode: 1700\n",
      "Episode: 1800\n",
      "Episode: 1900\n",
      "Episode: 2000\n",
      "Episode: 2100\n",
      "Episode: 2200\n",
      "Episode: 2300\n",
      "Episode: 2400\n",
      "Episode: 2500\n",
      "Episode: 2600\n",
      "Episode: 2700\n",
      "Episode: 2800\n",
      "Episode: 2900\n",
      "Episode: 3000\n",
      "Episode: 3100\n",
      "Episode: 3200\n",
      "Episode: 3300\n",
      "Episode: 3400\n",
      "Episode: 3500\n",
      "Episode: 3600\n",
      "Episode: 3700\n",
      "Episode: 3800\n",
      "Episode: 3900\n",
      "Episode: 4000\n",
      "Episode: 4100\n",
      "Episode: 4200\n",
      "Episode: 4300\n",
      "Episode: 4400\n",
      "Episode: 4500\n",
      "Episode: 4600\n",
      "Episode: 4700\n",
      "Episode: 4800\n",
      "Episode: 4900\n",
      "Episode: 5000\n",
      "Episode: 5100\n",
      "Episode: 5200\n",
      "Episode: 5300\n",
      "Episode: 5400\n",
      "Episode: 5500\n",
      "Episode: 5600\n",
      "Episode: 5700\n",
      "Episode: 5800\n",
      "Episode: 5900\n",
      "Episode: 6000\n",
      "Episode: 6100\n",
      "Episode: 6200\n",
      "Episode: 6300\n",
      "Episode: 6400\n",
      "Episode: 6500\n",
      "Episode: 6600\n",
      "Episode: 6700\n",
      "Episode: 6800\n",
      "Episode: 6900\n",
      "Episode: 7000\n",
      "Episode: 7100\n",
      "Episode: 7200\n",
      "Episode: 7300\n",
      "Episode: 7400\n",
      "Episode: 7500\n",
      "Episode: 7600\n",
      "Episode: 7700\n",
      "Episode: 7800\n",
      "Episode: 7900\n",
      "Episode: 8000\n",
      "Episode: 8100\n",
      "Episode: 8200\n",
      "Episode: 8300\n",
      "Episode: 8400\n",
      "Episode: 8500\n",
      "Episode: 8600\n",
      "Episode: 8700\n",
      "Episode: 8800\n",
      "Episode: 8900\n",
      "Episode: 9000\n",
      "Episode: 9100\n",
      "Episode: 9200\n",
      "Episode: 9300\n",
      "Episode: 9400\n",
      "Episode: 9500\n",
      "Episode: 9600\n",
      "Episode: 9700\n",
      "Episode: 9800\n",
      "Episode: 9900\n",
      "Episode: 10000\n",
      "Episode: 10100\n",
      "Episode: 10200\n",
      "Episode: 10300\n",
      "Episode: 10400\n",
      "Episode: 10500\n",
      "Episode: 10600\n",
      "Episode: 10700\n",
      "Episode: 10800\n",
      "Episode: 10900\n",
      "Episode: 11000\n",
      "Episode: 11100\n",
      "Episode: 11200\n",
      "Episode: 11300\n",
      "Episode: 11400\n",
      "Episode: 11500\n",
      "Episode: 11600\n",
      "Episode: 11700\n",
      "Episode: 11800\n",
      "Episode: 11900\n",
      "Episode: 12000\n",
      "Episode: 12100\n",
      "Episode: 12200\n",
      "Episode: 12300\n",
      "Episode: 12400\n",
      "Episode: 12500\n",
      "Episode: 12600\n",
      "Episode: 12700\n",
      "Episode: 12800\n",
      "Episode: 12900\n",
      "Episode: 13000\n",
      "Episode: 13100\n",
      "Episode: 13200\n",
      "Episode: 13300\n",
      "Episode: 13400\n",
      "Episode: 13500\n",
      "Episode: 13600\n",
      "Episode: 13700\n",
      "Episode: 13800\n",
      "Episode: 13900\n",
      "Episode: 14000\n",
      "Episode: 14100\n",
      "Episode: 14200\n",
      "Episode: 14300\n",
      "Episode: 14400\n",
      "Episode: 14500\n",
      "Episode: 14600\n",
      "Episode: 14700\n",
      "Episode: 14800\n",
      "Episode: 14900\n",
      "Episode: 15000\n",
      "Episode: 15100\n",
      "Episode: 15200\n",
      "Episode: 15300\n",
      "Episode: 15400\n",
      "Episode: 15500\n",
      "Episode: 15600\n",
      "Episode: 15700\n",
      "Episode: 15800\n",
      "Episode: 15900\n",
      "Episode: 16000\n",
      "Episode: 16100\n",
      "Episode: 16200\n",
      "Episode: 16300\n",
      "Episode: 16400\n",
      "Episode: 16500\n",
      "Episode: 16600\n",
      "Episode: 16700\n",
      "Episode: 16800\n",
      "Episode: 16900\n",
      "Episode: 17000\n",
      "Episode: 17100\n",
      "Episode: 17200\n",
      "Episode: 17300\n",
      "Episode: 17400\n",
      "Episode: 17500\n",
      "Episode: 17600\n",
      "Episode: 17700\n",
      "Episode: 17800\n",
      "Episode: 17900\n",
      "Episode: 18000\n",
      "Episode: 18100\n",
      "Episode: 18200\n",
      "Episode: 18300\n",
      "Episode: 18400\n",
      "Episode: 18500\n",
      "Episode: 18600\n",
      "Episode: 18700\n",
      "Episode: 18800\n",
      "Episode: 18900\n",
      "Episode: 19000\n",
      "Episode: 19100\n",
      "Episode: 19200\n",
      "Episode: 19300\n",
      "Episode: 19400\n",
      "Episode: 19500\n",
      "Episode: 19600\n",
      "Episode: 19700\n",
      "Episode: 19800\n",
      "Episode: 19900\n",
      "Training finished.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m---> 82\u001b[0m     action \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39margmax(q_table[state])\n\u001b[0;32m     83\u001b[0m     state, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy\n",
    "import random\n",
    "from os import system, name\n",
    "from time import sleep\n",
    "\n",
    "# Define function to clear console window.\n",
    "def clear(): \n",
    "  \n",
    "    # Clear on Windows.\n",
    "    if name == 'nt': \n",
    "        _ = system('cls')\n",
    "  \n",
    "    # Clear on Mac and Linux. (os.name is 'posix') \n",
    "    else: \n",
    "        _ = system('clear')\n",
    "\n",
    "clear()\n",
    "\n",
    "\"\"\"Setup\"\"\"\n",
    "\n",
    "env = gym.make(\"Taxi-v3\").env # Setup the Gym Environment\n",
    "\n",
    "# Make a new matrix filled with zeros.\n",
    "# The matrix will be 500x6 as there are 500 states and 6 actions.\n",
    "q_table = numpy.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "training_episodes = 20000 # Amount of times to run environment while training.\n",
    "display_episodes = 10 # Amount of times to run environment after training.\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.1 # Learning Rate\n",
    "gamma = 0.6 # Discount Rate\n",
    "epsilon = 0.1 # Chance of selecting a random action instead of maximising reward.\n",
    "\n",
    "# For plotting metrics\n",
    "all_epochs = []\n",
    "all_penalties = []\n",
    "\n",
    "\"\"\"Training the Agent\"\"\"\n",
    "\n",
    "for i in range(training_episodes):    \n",
    "    state = env.reset()[0] # Reset returns observation state and other info. We only need the state.\n",
    "    done = False\n",
    "    penalties, reward, = 0, 0\n",
    "    \n",
    "    while not done:\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = env.action_space.sample() # Pick a new action for this state.\n",
    "        else:\n",
    "            action = numpy.argmax(q_table[state]) # Pick the action which has previously given the highest reward.\n",
    "\n",
    "        next_state, reward, done, _, info = env.step(action) \n",
    "        \n",
    "        old_value = q_table[state, action] # Retrieve old value from the q-table.\n",
    "        next_max = numpy.max(q_table[next_state])\n",
    "\n",
    "        # Update q-value for current state.\n",
    "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "        q_table[state, action] = new_value\n",
    "\n",
    "        if reward == -10: # Checks if agent attempted to do an illegal action.\n",
    "            penalties += 1\n",
    "\n",
    "        state = next_state\n",
    "        \n",
    "    if i % 100 == 0: # Output number of completed episodes every 100 episodes.\n",
    "        print(f\"Episode: {i}\")\n",
    "\n",
    "print(\"Training finished.\\n\")\n",
    "\n",
    "\"\"\"Display and evaluate agent's performance after Q-learning.\"\"\"\n",
    "\n",
    "total_epochs, total_penalties = 0, 0\n",
    "\n",
    "for _ in range(display_episodes):\n",
    "    state = env.reset()\n",
    "    epochs, penalties, reward = 0, 0, 0   \n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = numpy.argmax(q_table[state])\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        epochs += 1\n",
    "        clear()\n",
    "        env.render()\n",
    "        print(f\"Timestep: {epochs}\")\n",
    "        print(f\"State: {state}\")\n",
    "        print(f\"Action: {action}\")\n",
    "        print(f\"Reward: {reward}\")\n",
    "        sleep(0.15) # Sleep so the user can see the \n",
    "\n",
    "    total_penalties += penalties\n",
    "    total_epochs += epochs\n",
    "\n",
    "print(f\"Results after {display_episodes} episodes:\")\n",
    "print(f\"Average timesteps per episode: {total_epochs / display_episodes}\")\n",
    "print(f\"Average penalties per episode: {total_penalties / display_episodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41c4ce31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 Total Reward: -924\n",
      "Episode 50 Total Reward: -40\n",
      "Episode 100 Total Reward: 13\n",
      "Episode 150 Total Reward: 8\n",
      "Episode 200 Total Reward: 8\n",
      "Episode 250 Total Reward: 10\n",
      "Episode 300 Total Reward: 10\n",
      "Episode 350 Total Reward: 11\n",
      "Episode 400 Total Reward: 6\n",
      "Episode 450 Total Reward: 5\n",
      "Episode 500 Total Reward: 6\n",
      "Episode 550 Total Reward: 4\n",
      "Episode 600 Total Reward: 4\n",
      "Episode 650 Total Reward: 1\n",
      "Episode 700 Total Reward: 10\n",
      "Episode 750 Total Reward: 9\n",
      "Episode 800 Total Reward: 7\n",
      "Episode 850 Total Reward: 4\n",
      "Episode 900 Total Reward: 6\n",
      "Episode 950 Total Reward: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 답\n",
    "import gym \n",
    "env = gym.make(\"Taxi-v3\" ) # , render_mode='human') \n",
    "\n",
    "import numpy as np       \n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])   #[ 총 상태 수, action 수 ]  즉, [500,6] \n",
    "\n",
    "G = 0 ;  rList =[]  \n",
    "dis = 0.618\n",
    "for episode in range(1000): \n",
    "\tdone = False\n",
    "\tG, reward = 0, 0\n",
    "\tstate = env.reset()[0] \n",
    "\twhile done != True:\n",
    "\t\taction = np.argmax(Q[state])\n",
    "\t\tstate2, reward, done, _, info = env.step(action) \n",
    "\t\tQ[state, action]  = dis * (reward + np.max(Q[state2])  )\n",
    "\t\tG += reward\n",
    "\t\tstate = state2     \n",
    "\trList.append(G) \n",
    "\tif episode % 50 == 0:\n",
    "\t\tprint('Episode {} Total Reward: {}'.format(episode, G))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(len(rList)), rList, color='b', alpha=0.4)\n",
    "plt.ylim(-200,50)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
